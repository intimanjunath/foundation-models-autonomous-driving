# Foundation Models: Transforming Autonomous Driving ğŸš—ğŸ¤–

Welcome to the official repository for my short story assignment based on the survey paper by Gao et al. (2024). This repository includes my Medium article, presentation slides, and YouTube video, clearly outlining the impact of Foundation Models on autonomous driving.

---

## ğŸ“Œ Overview

Foundation Models have dramatically reshaped autonomous driving by transitioning from traditional modular systems (perception, prediction, planning, control) to unified, multi-capable architectures. This repository explores these transformative modelsâ€”Large Language Models (LLMs), Vision Foundation Models (VFMs), and Multi-modal Foundation Models (MFMs)â€”highlighting their capabilities, current challenges, and future research directions.

---

## ğŸ“– Medium Article

- **Read the full article on Medium:**  
  [Foundation Models: Transforming Autonomous Driving](https://medium.com/@manjunatha.inti/foundation-models-transforming-autonomous-driving-5226a95ae62d)

---

## ğŸ“½ï¸ Google Slides Presentation

- **View Presentation:**  
  [Foundation Models - Google Slides](https://docs.google.com/presentation/d/e/2PACX-1vQm_JQEMkFfzHyj4P0EiQoLcf7zwelIqHjZgoYKijPg5IEOMQ9NO7jEY5deqlhrFCQR8BtTzTUZtrga/pub?start=true&loop=false&delayms=3000)

---

## ğŸ¬ Video Explanation

- **Watch the detailed video:**  
  (https://youtu.be/m9U4_sSI3Rk)

---

## ğŸ—‚ï¸ Repository Contents

- **Medium Article:** Original, rewritten summary and discussion on foundation models in autonomous driving.
- **Presentation Slides:** Concise, visual summary suitable for academic and industry presentations.
- **Video Explanation:** Comprehensive video walkthrough (15-25 min) explaining key points of the paper and related insights.

---

## ğŸ§  Topics Covered

- **Modular vs. Unified Architectures:** Challenges and benefits
- **Large Language Models (LLMs):** GPT-driven reasoning, trajectory prediction, and simulation
- **Vision Foundation Models (VFMs):** Enhanced perception and realistic scenario generation
- **Multi-modal Foundation Models (MFMs):** Real-time visual reasoning, spatial understanding, and end-to-end driving systems
- **Critical Challenges:** Hallucination, computational latency, data dependency
- **Future Roadmap:** Domain-specific fine-tuning, human-in-the-loop methods, 3D data integration

---

## ğŸ–¼ï¸ Illustrations & Figures

Essential visuals from Gao et al. (2024):

- **Figure 3:** Categorization of LLM research in autonomous driving.
<img width="408" alt="Screenshot 2025-05-07 at 4 24 04â€¯PM" src="https://github.com/user-attachments/assets/82e56a3e-63d1-4919-ae0f-18b7ad80adb1" />

- **Figure 4:** Applications and advancements of Vision Foundation Models.\
<img width="408" alt="Screenshot 2025-05-07 at 4 23 44â€¯PM" src="https://github.com/user-attachments/assets/e8df8ae8-dab8-4b91-9a55-fc4ec5736382" />

- **Figure 6:** Proposed future roadmap for foundation model research in AD.
<img width="408" alt="Screenshot 2025-05-07 at 4 23 02â€¯PM" src="https://github.com/user-attachments/assets/7dfe9cf3-60a5-4a70-ab98-35c4bdad44f3" />

---

## ğŸ“š References

- Gao, H., Wang, Z., Li, Y., Long, K., Yang, M., & Shen, Y. (2024).  
  **A Survey for Foundation Models in Autonomous Driving**.  
  [arXiv:2402.01105](https://arxiv.org/abs/2402.01105)

---

## âœ‰ï¸ Contact Information

- **Author:** Manjunatha Inti  
- **Medium:** [manjunatha.inti](https://medium.com/@manjunatha.inti)

Feel free to reach out for any feedback or queries. Thanks for exploring!

âœ¨ Happy Learning! âœ¨
